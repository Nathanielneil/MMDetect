"""
æ‰‹åŠ¿è¯†åˆ«é«˜çº§å¯è§†åŒ–æµ‹è¯•è„šæœ¬
æ˜¾ç¤ºæŒ‡å°–è½¨è¿¹ã€æ¸å˜éª¨æ¶ã€å‘å…‰æ•ˆæœç­‰
"""

import cv2
import logging
import sys
from src.detectors.gesture_detector import GestureDetector

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)

    detector = GestureDetector()

    if detector.initialize():
        cap = cv2.VideoCapture(0)

        print("\n" + "="*60)
        print("  æ‰‹åŠ¿è¯†åˆ« - é«˜çº§å¯è§†åŒ–æ¨¡å¼")
        print("="*60)
        print("\næ”¯æŒçš„æ‰‹åŠ¿:")
        print("  ğŸ–ï¸  å¼ å¼€æ‰‹æŒ  (5æŒ‡) -> TAKEOFF   (èµ·é£)")
        print("  âœŠ  æ¡æ‹³      (0æŒ‡) -> LAND      (é™è½)")
        print("  â˜ï¸  å•æŒ‡      (1æŒ‡) -> HOVER     (æ‚¬åœ)")
        print("  âœŒï¸  Vå­—æ‰‹åŠ¿   (2æŒ‡) -> EXPLORE   (æ¢ç´¢)")
        print("  ğŸ¤Ÿ  ä¸‰æŒ‡      (3æŒ‡) -> FORMATION (ç¼–é˜Ÿ)")
        print("\nå¯è§†åŒ–ç‰¹æ•ˆ:")
        print("  âœ¨ æ¸å˜è‰²éª¨æ¶ (æ ¹æ®æ‰‹éƒ¨æ·±åº¦)")
        print("  ğŸ’« å‘å…‰å…³é”®ç‚¹ (æŒ‡å°–è„‰å†²æ•ˆæœ)")
        print("  ğŸŒˆ æŒ‡å°–è½¨è¿¹   (ç´«è‰²åˆ°ç²‰è‰²æ¸éšæ‹–å°¾)")
        print("  ğŸ’“ æ‰‹æŒè„‰å†²   (é’è“è‰²å‘¼å¸åŠ¨ç”»)")
        print("\næ“ä½œæç¤º:")
        print("  - è·ç¦»æ‘„åƒå¤´ 30-60cm")
        print("  - æ‰‹æ”¾åœ¨ç”»é¢ä¸­å¿ƒ")
        print("  - ç§»åŠ¨æ‰‹æŒ‡è§‚å¯Ÿè½¨è¿¹æ•ˆæœ")
        print("  - æŒ‰ 'q' é€€å‡º")
        print("="*60 + "\n")

        while cap.isOpened():
            success, frame = cap.read()
            if not success:
                print("æ— æ³•è¯»å–æ‘„åƒå¤´å¸§")
                break

            # è¿è¡Œæ£€æµ‹
            command = detector.run(frame)

            # è·å–å›¾åƒå°ºå¯¸
            h, w = frame.shape[:2]

            # ä½¿ç”¨é«˜çº§å¯è§†åŒ–
            if hasattr(detector, '_last_detection_result') and detector._last_detection_result:
                landmarks = detector._last_detection_result.get('landmarks')
                if landmarks:
                    # è°ƒç”¨é«˜çº§å¯è§†åŒ–æ–¹æ³• - æ˜¾ç¤ºæŒ‡å°–è½¨è¿¹ç­‰ç‰¹æ•ˆ
                    frame = detector.visualize_advanced(frame, landmarks, h, w)

                    # è·å–è°ƒè¯•ä¿¡æ¯
                    landmarks_list = []
                    for lm in landmarks.landmark:
                        landmarks_list.append([lm.x, lm.y, lm.z])

                    # è·å–å·¦å³æ‰‹ä¿¡æ¯
                    handedness = detector._last_detection_result.get('handedness', 'Right')
                    fingers_count = detector._count_fingers_up(landmarks_list, handedness)
                    is_fist = detector._is_fist(landmarks_list)

                    # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯ï¼ˆåŒ…å«å·¦å³æ‰‹ï¼‰
                    debug_text = f"{handedness} Hand | Fingers: {fingers_count}"
                    if is_fist:
                        debug_text += " [FIST]"

                    cv2.putText(
                        frame,
                        debug_text,
                        (10, 110),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (255, 255, 0),
                        2
                    )

            # æ˜¾ç¤ºæŒ‡ä»¤ä¿¡æ¯
            if command and command['confidence'] > 0.5:
                # è·å–æ‰‹åŠ¿ä¿¡æ¯
                gesture_type = command['parameters'].get('gesture_type', 'unknown')
                cmd_name = command['command'].upper() if isinstance(command['command'], str) else command['command'].name

                # æ£€æŸ¥æ˜¯å¦ç»è¿‡å¹³æ»‘å¤„ç†
                is_smoothed = command['parameters'].get('smoothed', False)
                stability = command['parameters'].get('stability', 0.0)
                is_holding = command['parameters'].get('holding', False)

                # æ˜¾ç¤ºæŒ‡ä»¤ï¼ˆæ›´æ¸…æ™°çš„æ ¼å¼ï¼‰
                display_text = f"{gesture_type} -> {cmd_name}"
                if is_holding:
                    display_text += " [HOLD]"
                elif is_smoothed:
                    display_text += f" [S:{stability:.1f}]"

                color = (0, 255, 0) if stability > 0.8 else (0, 255, 255)

                cv2.putText(
                    frame,
                    display_text,
                    (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.9,
                    color,
                    2
                )

                # æ˜¾ç¤ºç½®ä¿¡åº¦
                cv2.putText(
                    frame,
                    f"Confidence: {command['confidence']:.2f}",
                    (10, 70),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.7,
                    color,
                    2
                )

                # ç»ˆç«¯æ‰“å°
                status = ""
                if is_holding:
                    status = "[ä¿æŒ]"
                elif is_smoothed:
                    status = f"[ç¨³å®šåº¦:{stability:.2f}]"

                print(f"âœ“ {gesture_type:15s} -> {cmd_name:12s} (ç½®ä¿¡åº¦: {command['confidence']:.2f}) {status}")

            elif command and command['confidence'] == 0.0:
                # æœªæ£€æµ‹åˆ°æ‰‹éƒ¨
                cv2.putText(
                    frame,
                    "No hand detected - Move hand into view",
                    (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.7,
                    (0, 0, 255),
                    2
                )

            # æ·»åŠ æ ‡é¢˜
            cv2.putText(
                frame,
                "Advanced Gesture Visualization",
                (10, h - 20),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (200, 200, 200),
                1
            )

            cv2.imshow('Gesture Detection - Advanced Mode', frame)

            if cv2.waitKey(5) & 0xFF == ord('q'):
                break

        cap.release()
        cv2.destroyAllWindows()
        detector.shutdown()
        print("\nâœ“ ç¨‹åºå·²é€€å‡º")
    else:
        print("âœ— æ‰‹åŠ¿æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥ï¼")
        sys.exit(1)
