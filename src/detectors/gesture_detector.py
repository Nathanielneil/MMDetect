"""
æ‰‹åŠ¿è¯†åˆ«æ£€æµ‹å™¨
ä½¿ç”¨MediaPipe Hands + ç®€å•åˆ†ç±»å™¨
"""

import cv2
import numpy as np
from typing import Dict, Any, Optional, List, Deque
from collections import deque
import time
import logging

try:
    import mediapipe as mp
except ImportError:
    logging.warning("MediaPipeæœªå®‰è£…,æ‰‹åŠ¿æ£€æµ‹å™¨å°†æ— æ³•ä½¿ç”¨")

# æ”¯æŒç›´æ¥è¿è¡Œå’Œæ¨¡å—å¯¼å…¥ä¸¤ç§æ–¹å¼
try:
    from .base_detector import BaseDetector, CommandType, ModalityType
except ImportError:
    import sys
    import os
    sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))
    from src.detectors.base_detector import BaseDetector, CommandType, ModalityType


class GestureDetector(BaseDetector):
    """
    æ‰‹åŠ¿è¯†åˆ«æ£€æµ‹å™¨

    ä½¿ç”¨MediaPipe Handsæ£€æµ‹æ‰‹éƒ¨å…³é”®ç‚¹,é€šè¿‡æ‰‹åŠ¿è§„åˆ™æ˜ å°„åˆ°æŒ‡ä»¤
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–æ‰‹åŠ¿æ£€æµ‹å™¨

        Args:
            config: é…ç½®å­—å…¸,åŒ…å«:
                - min_detection_confidence: æœ€å°æ£€æµ‹ç½®ä¿¡åº¦(é»˜è®¤0.7)
                - min_tracking_confidence: æœ€å°è·Ÿè¸ªç½®ä¿¡åº¦(é»˜è®¤0.5)
                - max_num_hands: æœ€å¤§æ‰‹æ•°(é»˜è®¤1)
        """
        super().__init__(ModalityType.GESTURE, config)

        self.min_detection_confidence = self.config.get('min_detection_confidence', 0.5)  # é™ä½æ£€æµ‹é˜ˆå€¼
        self.min_tracking_confidence = self.config.get('min_tracking_confidence', 0.5)
        self.max_num_hands = self.config.get('max_num_hands', 1)

        self.mp_hands = None
        self.hands = None
        self.mp_draw = None

        # æ—¶åºå¹³æ»‘å‚æ•°
        self.history_window_size = self.config.get('history_window_size', 5)  # å†å²å¸§çª—å£å¤§å°
        self.min_consecutive_frames = self.config.get('min_consecutive_frames', 3)  # æœ€å°è¿ç»­å¸§æ•°
        self.command_timeout = self.config.get('command_timeout', 1.0)  # æŒ‡ä»¤è¶…æ—¶æ—¶é—´(ç§’)

        # å†å²è®°å½•
        self.command_history: Deque = deque(maxlen=self.history_window_size)
        self.last_stable_command = None  # ä¸Šä¸€æ¬¡ç¨³å®šçš„æŒ‡ä»¤
        self.last_stable_time = 0  # ä¸Šä¸€æ¬¡ç¨³å®šæŒ‡ä»¤çš„æ—¶é—´
        self.current_command_count = 0  # å½“å‰æŒ‡ä»¤çš„è¿ç»­å‡ºç°æ¬¡æ•°
        self.current_command_type = None  # å½“å‰æ­£åœ¨ç»Ÿè®¡çš„æŒ‡ä»¤ç±»å‹

        # å¯è§†åŒ–æ•ˆæœå‚æ•°
        self.enable_glow = self.config.get('enable_glow', True)  # å‘å…‰æ•ˆæœ
        self.enable_trails = self.config.get('enable_trails', True)  # è½¨è¿¹æ•ˆæœ
        self.trail_length = self.config.get('trail_length', 20)  # è½¨è¿¹é•¿åº¦
        self.fingertip_trails = {i: deque(maxlen=self.trail_length) for i in [4, 8, 12, 16, 20]}  # 5ä¸ªæŒ‡å°–çš„è½¨è¿¹
        self.pulse_phase = 0  # è„‰å†²åŠ¨ç”»ç›¸ä½

    def initialize(self) -> bool:
        """åˆå§‹åŒ–MediaPipe Hands"""
        try:
            self.mp_hands = mp.solutions.hands
            self.mp_draw = mp.solutions.drawing_utils

            self.hands = self.mp_hands.Hands(
                static_image_mode=False,
                max_num_hands=self.max_num_hands,
                min_detection_confidence=self.min_detection_confidence,
                min_tracking_confidence=self.min_tracking_confidence
            )

            self.is_initialized = True
            self.logger.info("æ‰‹åŠ¿æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")
            return True

        except Exception as e:
            self.logger.error(f"æ‰‹åŠ¿æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return False

    def preprocess(self, image: np.ndarray) -> np.ndarray:
        """
        é¢„å¤„ç†å›¾åƒ

        Args:
            image: BGRå›¾åƒ

        Returns:
            np.ndarray: RGBå›¾åƒ
        """
        # MediaPipeéœ€è¦RGBæ ¼å¼
        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    def detect(self, image_rgb: np.ndarray) -> Dict[str, Any]:
        """
        æ£€æµ‹æ‰‹éƒ¨å…³é”®ç‚¹

        Args:
            image_rgb: RGBå›¾åƒ

        Returns:
            Dict: æ£€æµ‹ç»“æœ,åŒ…å«å…³é”®ç‚¹åæ ‡
        """
        results = self.hands.process(image_rgb)

        detection_result = {
            'detected': False,
            'landmarks': None,
            'handedness': None
        }

        if results.multi_hand_landmarks:
            detection_result['detected'] = True
            detection_result['landmarks'] = results.multi_hand_landmarks[0]
            if results.multi_handedness:
                detection_result['handedness'] = results.multi_handedness[0].classification[0].label

        # ä¿å­˜æœ€åä¸€æ¬¡æ£€æµ‹ç»“æœä¾›å¯è§†åŒ–ä½¿ç”¨
        self._last_detection_result = detection_result

        return detection_result

    def postprocess(self, detection_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        å°†æ‰‹åŠ¿è¯†åˆ«ä¸ºæŒ‡ä»¤ï¼ˆå¸¦æ—¶åºå¹³æ»‘ï¼‰

        Args:
            detection_result: æ‰‹éƒ¨æ£€æµ‹ç»“æœ

        Returns:
            Dict: æ ‡å‡†åŒ–æŒ‡ä»¤å­—å…¸ï¼ˆç»è¿‡å¹³æ»‘å¤„ç†ï¼‰
        """
        if not detection_result['detected']:
            raw_command = self.create_command_dict(
                CommandType.HOVER,
                confidence=0.0,
                parameters={'reason': 'no_hand_detected'}
            )
        else:
            landmarks = detection_result['landmarks']

            # æå–å…³é”®ç‚¹
            landmarks_list = []
            for lm in landmarks.landmark:
                landmarks_list.append([lm.x, lm.y, lm.z])

            # è¯†åˆ«æ‰‹åŠ¿ï¼ˆä¼ å…¥å·¦å³æ‰‹ä¿¡æ¯ï¼‰
            handedness = detection_result.get('handedness', 'Right')
            gesture_type, confidence = self._classify_gesture(landmarks_list, handedness)

            # æ˜ å°„åˆ°æŒ‡ä»¤
            command_type = self._gesture_to_command(gesture_type)

            parameters = {
                'gesture_type': gesture_type,
                'handedness': handedness
            }

            raw_command = self.create_command_dict(command_type, confidence, parameters)

        # åº”ç”¨æ—¶åºå¹³æ»‘
        smoothed_command = self._apply_temporal_smoothing(raw_command)

        return smoothed_command

    def _classify_gesture(self, landmarks: List[List[float]], handedness: str = 'Right') -> tuple:
        """
        åˆ†ç±»æ‰‹åŠ¿

        Args:
            landmarks: 21ä¸ªæ‰‹éƒ¨å…³é”®ç‚¹åæ ‡
            handedness: å·¦æ‰‹('Left')æˆ–å³æ‰‹('Right')

        Returns:
            tuple: (æ‰‹åŠ¿ç±»å‹, ç½®ä¿¡åº¦)
        """
        # ä¼˜å…ˆæ£€æµ‹æ¡æ‹³ï¼ˆä½¿ç”¨ä¸“é—¨çš„åˆ¤æ–­å‡½æ•°ï¼‰
        if self._is_fist(landmarks):
            return 'fist', 0.95  # é«˜ç½®ä¿¡åº¦

        # è®¡ç®—æ‰‹æŒ‡ä¼¸å±•çŠ¶æ€ï¼ˆè€ƒè™‘å·¦å³æ‰‹ï¼‰
        fingers_up = self._count_fingers_up(landmarks, handedness)

        # è§„åˆ™åˆ†ç±»
        if fingers_up == 5:  # å¼ å¼€æ‰‹æŒ
            return 'open_palm', 0.9
        elif fingers_up == 0:  # æ‰‹æŒ‡æ•°ä¸º0ä½†ä¸æ˜¯æ¡æ‹³ï¼ˆå¯èƒ½æ˜¯æ£€æµ‹å¼‚å¸¸ï¼‰
            return 'fist', 0.7  # é™ä½ç½®ä¿¡åº¦
        elif fingers_up == 1:  # ç«–èµ·ä¸€æ ¹æ‰‹æŒ‡
            return 'one_finger', 0.85
        elif fingers_up == 2:  # Vå­—æ‰‹åŠ¿
            if self._is_v_gesture(landmarks):
                return 'v_sign', 0.85
            return 'two_fingers', 0.8
        elif fingers_up == 3:
            return 'three_fingers', 0.8
        elif fingers_up == 4:
            return 'four_fingers', 0.8
        else:
            return 'unknown', 0.3

    def _count_fingers_up(self, landmarks: List[List[float]], handedness: str = 'Right') -> int:
        """
        è®¡ç®—ä¼¸å±•æ‰‹æŒ‡æ•°é‡

        Args:
            landmarks: æ‰‹éƒ¨å…³é”®ç‚¹
            handedness: å·¦æ‰‹('Left')æˆ–å³æ‰‹('Right')

        Returns:
            int: ä¼¸å±•æ‰‹æŒ‡æ•°é‡
        """
        # MediaPipeæ‰‹éƒ¨å…³é”®ç‚¹ç´¢å¼•
        # 0: æ‰‹è…•, 4: æ‹‡æŒ‡å°–, 8: é£ŸæŒ‡å°–, 12: ä¸­æŒ‡å°–, 16: æ— åæŒ‡å°–, 20: å°æŒ‡å°–
        finger_tips = [4, 8, 12, 16, 20]
        finger_mcp = [2, 5, 9, 13, 17]  # MCPå…³èŠ‚ï¼ˆæŒæŒ‡å…³èŠ‚ï¼‰

        count = 0

        # æ‹‡æŒ‡: æ ¹æ®å·¦å³æ‰‹åˆ¤æ–­
        thumb_tip = landmarks[4]
        thumb_mcp = landmarks[2]

        if handedness == 'Right':
            # å³æ‰‹ï¼šæ‹‡æŒ‡ä¼¸å±•æ—¶xåæ ‡æ›´å°ï¼ˆå‘å·¦ï¼‰
            thumb_is_open = thumb_tip[0] < thumb_mcp[0] - 0.04
        else:  # Left
            # å·¦æ‰‹ï¼šæ‹‡æŒ‡ä¼¸å±•æ—¶xåæ ‡æ›´å¤§ï¼ˆå‘å³ï¼‰
            thumb_is_open = thumb_tip[0] > thumb_mcp[0] + 0.04

        if thumb_is_open:
            count += 1

        # å…¶ä»–å››æŒ‡: ä½¿ç”¨yåæ ‡åˆ¤æ–­ï¼ˆå·¦å³æ‰‹ç›¸åŒï¼‰
        for i in range(1, 5):
            tip = landmarks[finger_tips[i]]
            mcp = landmarks[finger_mcp[i]]

            # æ‰‹æŒ‡ä¼¸å±•ï¼šæŒ‡å°–æ˜æ˜¾é«˜äºMCPå…³èŠ‚
            if tip[1] < mcp[1] - 0.03:  # yè½´å‘ä¸‹ä¸ºæ­£
                count += 1

        return count

    def _is_fist(self, landmarks: List[List[float]]) -> bool:
        """
        ä¸“é—¨åˆ¤æ–­æ˜¯å¦ä¸ºæ¡æ‹³

        Args:
            landmarks: æ‰‹éƒ¨å…³é”®ç‚¹

        Returns:
            bool: æ˜¯å¦ä¸ºæ¡æ‹³
        """
        # ç­–ç•¥ï¼šæ‰€æœ‰æŒ‡å°–éƒ½é è¿‘æ‰‹æŒä¸­å¿ƒ
        palm_center_y = (landmarks[0][1] + landmarks[9][1]) / 2  # æ‰‹è…•å’Œä¸­æŒ‡MCPçš„ä¸­ç‚¹

        # æ£€æŸ¥æ‰€æœ‰æŒ‡å°–æ˜¯å¦éƒ½ä½äºï¼ˆæˆ–æ¥è¿‘ï¼‰æ‰‹æŒä¸­å¿ƒ
        finger_tips = [4, 8, 12, 16, 20]
        tips_below_palm = 0

        for tip_idx in finger_tips:
            if landmarks[tip_idx][1] >= palm_center_y - 0.05:  # æŒ‡å°–åœ¨æ‰‹æŒä¸­å¿ƒé™„è¿‘æˆ–ä¸‹æ–¹
                tips_below_palm += 1

        # è‡³å°‘4æ ¹æ‰‹æŒ‡çš„æŒ‡å°–éƒ½æ”¶èµ·æ¥ï¼Œæ‰ç®—æ¡æ‹³
        return tips_below_palm >= 4

    def _is_v_gesture(self, landmarks: List[List[float]]) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºVå­—æ‰‹åŠ¿

        Args:
            landmarks: æ‰‹éƒ¨å…³é”®ç‚¹

        Returns:
            bool: æ˜¯å¦ä¸ºVå­—æ‰‹åŠ¿
        """
        # æ£€æŸ¥é£ŸæŒ‡å’Œä¸­æŒ‡ä¼¸å±•,å…¶ä»–æ‰‹æŒ‡æ”¶èµ·
        index_up = landmarks[8][1] < landmarks[6][1]
        middle_up = landmarks[12][1] < landmarks[10][1]
        ring_down = landmarks[16][1] > landmarks[14][1]
        pinky_down = landmarks[20][1] > landmarks[18][1]

        return index_up and middle_up and ring_down and pinky_down

    def _gesture_to_command(self, gesture_type: str) -> CommandType:
        """
        æ‰‹åŠ¿åˆ°æŒ‡ä»¤çš„æ˜ å°„

        Args:
            gesture_type: æ‰‹åŠ¿ç±»å‹

        Returns:
            CommandType: æŒ‡ä»¤ç±»å‹
        """
        gesture_map = {
            'open_palm': CommandType.TAKEOFF,      # å¼ å¼€æ‰‹æŒ=èµ·é£
            'fist': CommandType.LAND,              # æ¡æ‹³=é™è½
            'one_finger': CommandType.HOVER,       # ä¸€æ ¹æ‰‹æŒ‡=æ‚¬åœ
            'v_sign': CommandType.EXPLORE,         # Vå­—=æ¢ç´¢
            'three_fingers': CommandType.FORMATION # ä¸‰æ ¹æ‰‹æŒ‡=ç¼–é˜Ÿ
        }

        return gesture_map.get(gesture_type, CommandType.HOVER)

    def _apply_temporal_smoothing(self, raw_command: Dict[str, Any]) -> Dict[str, Any]:
        """
        åº”ç”¨æ—¶åºå¹³æ»‘ï¼Œå‡å°‘å¸§é—´æŠ–åŠ¨

        ç­–ç•¥ï¼š
        1. ç»´æŠ¤æœ€è¿‘Nå¸§çš„æŒ‡ä»¤å†å²
        2. åªæœ‰è¿ç»­Må¸§éƒ½æ˜¯åŒä¸€æŒ‡ä»¤ï¼Œæ‰è®¤ä¸ºæ˜¯ç¨³å®šçš„
        3. å¯¹äºå…³é”®æŒ‡ä»¤(LAND/TAKEOFF)ï¼Œè¦æ±‚æ›´é«˜çš„ç¨³å®šæ€§

        Args:
            raw_command: åŸå§‹æ£€æµ‹åˆ°çš„æŒ‡ä»¤

        Returns:
            Dict: å¹³æ»‘åçš„æŒ‡ä»¤
        """
        current_time = time.time()
        command_type = raw_command['command']

        # å°†å½“å‰æŒ‡ä»¤åŠ å…¥å†å²
        self.command_history.append({
            'command': command_type,
            'confidence': raw_command['confidence'],
            'time': current_time
        })

        # ç»Ÿè®¡å†å²çª—å£ä¸­æ¯ä¸ªæŒ‡ä»¤çš„å‡ºç°æ¬¡æ•°
        command_counts = {}
        for cmd in self.command_history:
            cmd_type = cmd['command']
            command_counts[cmd_type] = command_counts.get(cmd_type, 0) + 1

        # æ‰¾å‡ºå‡ºç°æœ€å¤šçš„æŒ‡ä»¤
        if command_counts:
            most_common_command = max(command_counts.items(), key=lambda x: x[1])
            most_common_type, count = most_common_command
        else:
            # æ²¡æœ‰å†å²ï¼Œè¿”å›å½“å‰æŒ‡ä»¤
            return raw_command

        # åˆ¤æ–­æ˜¯å¦ç¨³å®šï¼ˆè¿ç»­å‡ºç°ï¼‰
        is_stable = False

        # æ£€æŸ¥æœ€è¿‘çš„å¸§æ˜¯å¦è¿ç»­éƒ½æ˜¯è¿™ä¸ªæŒ‡ä»¤
        recent_commands = list(self.command_history)[-self.min_consecutive_frames:]
        if len(recent_commands) >= self.min_consecutive_frames:
            if all(cmd['command'] == most_common_type for cmd in recent_commands):
                is_stable = True

        # å¯¹äºå±é™©æŒ‡ä»¤ï¼ˆLAND/TAKEOFFï¼‰ï¼Œè¦æ±‚æ›´ä¸¥æ ¼
        dangerous_commands = [CommandType.LAND, CommandType.TAKEOFF]
        if most_common_type in dangerous_commands:
            # è¦æ±‚æ‰€æœ‰å†å²å¸§éƒ½æ˜¯è¿™ä¸ªæŒ‡ä»¤
            if count == len(self.command_history) and count >= self.min_consecutive_frames:
                is_stable = True
            else:
                is_stable = False

        # å†³å®šè¿”å›å“ªä¸ªæŒ‡ä»¤
        if is_stable:
            # ç¨³å®šçš„æ–°æŒ‡ä»¤
            self.last_stable_command = most_common_type
            self.last_stable_time = current_time

            # æ›´æ–°åŸå§‹æŒ‡ä»¤çš„commandå­—æ®µ
            smoothed_command = raw_command.copy()
            smoothed_command['command'] = most_common_type
            smoothed_command['parameters']['smoothed'] = True
            smoothed_command['parameters']['stability'] = count / len(self.command_history)
            return smoothed_command

        elif self.last_stable_command is not None:
            # ä¸ç¨³å®šï¼Œè¿”å›ä¸Šä¸€æ¬¡ç¨³å®šçš„æŒ‡ä»¤
            # ä½†æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if current_time - self.last_stable_time < self.command_timeout:
                smoothed_command = raw_command.copy()
                smoothed_command['command'] = self.last_stable_command
                smoothed_command['parameters']['smoothed'] = True
                smoothed_command['parameters']['holding'] = True
                smoothed_command['parameters']['stability'] = 0.5
                return smoothed_command
            else:
                # è¶…æ—¶äº†ï¼Œæ¸…é™¤å†å²
                self.last_stable_command = None
                self.command_history.clear()
                return raw_command
        else:
            # æ²¡æœ‰ç¨³å®šçš„å†å²æŒ‡ä»¤ï¼Œè¿”å›HOVERï¼ˆå®‰å…¨ï¼‰
            safe_command = raw_command.copy()
            safe_command['command'] = CommandType.HOVER
            safe_command['parameters']['smoothed'] = True
            safe_command['parameters']['unstable'] = True
            return safe_command

    def visualize(self, image: np.ndarray, landmarks) -> np.ndarray:
        """
        å¯è§†åŒ–æ‰‹éƒ¨å…³é”®ç‚¹ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰

        Args:
            image: BGRå›¾åƒ
            landmarks: æ‰‹éƒ¨å…³é”®ç‚¹

        Returns:
            np.ndarray: å¸¦æœ‰æ ‡æ³¨çš„å›¾åƒ
        """
        if landmarks:
            self.mp_draw.draw_landmarks(
                image,
                landmarks,
                self.mp_hands.HAND_CONNECTIONS
            )
        return image

    def visualize_advanced(self, image: np.ndarray, landmarks, h: int, w: int) -> np.ndarray:
        """
        é«˜çº§å¯è§†åŒ– - ç§‘æŠ€æ„Ÿæ•ˆæœ

        Args:
            image: BGRå›¾åƒ
            landmarks: æ‰‹éƒ¨å…³é”®ç‚¹
            h: å›¾åƒé«˜åº¦
            w: å›¾åƒå®½åº¦

        Returns:
            np.ndarray: å¸¦æœ‰é«˜çº§ç‰¹æ•ˆçš„å›¾åƒ
        """
        if not landmarks:
            return image

        # åˆ›å»ºå åŠ å±‚ï¼ˆç”¨äºé€æ˜æ•ˆæœï¼‰
        overlay = image.copy()

        # è·å–å…³é”®ç‚¹åæ ‡
        landmark_points = []
        for lm in landmarks.landmark:
            x, y, z = int(lm.x * w), int(lm.y * h), lm.z
            landmark_points.append((x, y, z))

        # 1. ç»˜åˆ¶æ¸å˜è‰²éª¨æ¶
        self._draw_gradient_skeleton(overlay, landmark_points)

        # 2. ç»˜åˆ¶å‘å…‰å…³é”®ç‚¹
        if self.enable_glow:
            self._draw_glowing_landmarks(overlay, landmark_points)

        # 3. ç»˜åˆ¶æŒ‡å°–è½¨è¿¹
        if self.enable_trails:
            self._draw_fingertip_trails(overlay, landmark_points)

        # 4. ç»˜åˆ¶æ‰‹æŒä¸­å¿ƒè„‰å†²
        self._draw_palm_pulse(overlay, landmark_points)

        # æ··åˆå åŠ å±‚å’ŒåŸå›¾
        cv2.addWeighted(overlay, 0.7, image, 0.3, 0, image)

        return image

    def _draw_gradient_skeleton(self, image: np.ndarray, points: List[tuple]):
        """ç»˜åˆ¶æ¸å˜è‰²éª¨æ¶"""
        # MediaPipeæ‰‹éƒ¨è¿æ¥å…³ç³»
        connections = [
            # æ‹‡æŒ‡
            (0, 1), (1, 2), (2, 3), (3, 4),
            # é£ŸæŒ‡
            (0, 5), (5, 6), (6, 7), (7, 8),
            # ä¸­æŒ‡
            (0, 9), (9, 10), (10, 11), (11, 12),
            # æ— åæŒ‡
            (0, 13), (13, 14), (14, 15), (15, 16),
            # å°æŒ‡
            (0, 17), (17, 18), (18, 19), (19, 20),
            # æ‰‹æŒ
            (5, 9), (9, 13), (13, 17)
        ]

        for start_idx, end_idx in connections:
            if start_idx < len(points) and end_idx < len(points):
                start = points[start_idx]
                end = points[end_idx]

                # æ ¹æ®æ·±åº¦(z)è®¡ç®—é¢œè‰² - è¶Šè¿‘è¶Šäº®
                depth_start = max(0, min(1, (start[2] + 0.1) * 5))  # å½’ä¸€åŒ–åˆ°0-1
                depth_end = max(0, min(1, (end[2] + 0.1) * 5))

                # æ¸å˜è‰²: è“è‰² -> é’è‰² -> ç»¿è‰²
                color_start = self._get_depth_color(depth_start)
                color_end = self._get_depth_color(depth_end)

                # ç»˜åˆ¶æ¸å˜çº¿æ¡
                self._draw_gradient_line(image, (start[0], start[1]), (end[0], end[1]),
                                        color_start, color_end, thickness=3)

    def _draw_glowing_landmarks(self, image: np.ndarray, points: List[tuple]):
        """ç»˜åˆ¶å‘å…‰å…³é”®ç‚¹"""
        # æŒ‡å°–ç´¢å¼•
        fingertips = [4, 8, 12, 16, 20]

        # è„‰å†²æ•ˆæœ
        self.pulse_phase = (self.pulse_phase + 0.1) % (2 * np.pi)
        pulse = int(abs(np.sin(self.pulse_phase)) * 3) + 2

        for idx, (x, y, z) in enumerate(points):
            if idx in fingertips:
                # æŒ‡å°– - æ›´äº®æ›´å¤§
                radius = 8 + pulse
                glow_radius = 15 + pulse
                color = (0, 255, 255)  # é»„è‰²
            else:
                # æ™®é€šå…³é”®ç‚¹
                radius = 4
                glow_radius = 8
                color = (255, 200, 100)  # é’è‰²

            # å¤–åœˆå…‰æ™•
            cv2.circle(image, (x, y), glow_radius, color, -1)
            # å†…åœˆæ ¸å¿ƒï¼ˆæ›´äº®ï¼‰
            cv2.circle(image, (x, y), radius, (255, 255, 255), -1)

    def _draw_fingertip_trails(self, image: np.ndarray, points: List[tuple]):
        """ç»˜åˆ¶æŒ‡å°–è½¨è¿¹"""
        fingertips = [4, 8, 12, 16, 20]

        for tip_idx in fingertips:
            if tip_idx < len(points):
                x, y, z = points[tip_idx]

                # æ·»åŠ å½“å‰ä½ç½®åˆ°è½¨è¿¹
                self.fingertip_trails[tip_idx].append((x, y))

                # ç»˜åˆ¶è½¨è¿¹ï¼ˆæ¸éšæ•ˆæœï¼‰
                trail = list(self.fingertip_trails[tip_idx])
                for i in range(len(trail) - 1):
                    # é€æ˜åº¦ä»æ—§åˆ°æ–°é€’å¢
                    alpha = int(255 * (i + 1) / len(trail))
                    thickness = max(1, int(3 * (i + 1) / len(trail)))

                    # é¢œè‰²ï¼šç´«è‰²åˆ°ç²‰è‰²æ¸å˜
                    color = (alpha, 0, 255 - alpha // 2)

                    cv2.line(image, trail[i], trail[i + 1], color, thickness)

    def _draw_palm_pulse(self, image: np.ndarray, points: List[tuple]):
        """ç»˜åˆ¶æ‰‹æŒä¸­å¿ƒè„‰å†²æ•ˆæœï¼ˆä½è°ƒç‰ˆæœ¬ï¼‰"""
        # æ‰‹æŒä¸­å¿ƒ = å…³é”®ç‚¹0, 5, 9, 13, 17çš„å¹³å‡ä½ç½®
        palm_indices = [0, 5, 9, 13, 17]
        palm_points = [points[i] for i in palm_indices if i < len(points)]

        if palm_points:
            palm_x = int(np.mean([p[0] for p in palm_points]))
            palm_y = int(np.mean([p[1] for p in palm_points]))

            # è„‰å†²åŠå¾„ï¼ˆå‡å°å¹…åº¦ï¼‰
            pulse_radius = int(35 + 5 * abs(np.sin(self.pulse_phase)))

            # ç»˜åˆ¶å•å±‚ç»†çº¿åœ†ç¯ï¼Œé¢œè‰²ä¸éª¨æ¶åè°ƒï¼ˆé’è“è‰²ç³»ï¼‰
            # ä½¿ç”¨åŠé€æ˜é’è‰²ï¼Œä¸æ·±åº¦æ¸å˜éª¨æ¶é¢œè‰²åè°ƒ
            alpha = int(60 + 40 * abs(np.sin(self.pulse_phase)))  # 60-100åŠ¨æ€é€æ˜åº¦
            color = (200, 180, alpha)  # é’è“è‰²ï¼Œä½é¥±å’Œåº¦
            cv2.circle(image, (palm_x, palm_y), pulse_radius, color, 1)  # ç»†çº¿

    def _get_depth_color(self, depth: float) -> tuple:
        """æ ¹æ®æ·±åº¦è·å–æ¸å˜è‰²"""
        # æ·±åº¦ 0-1 æ˜ å°„åˆ°é¢œè‰²
        # è¿‘: é»„è‰² (0, 255, 255)
        # ä¸­: é’è‰² (255, 255, 0)
        # è¿œ: è“è‰² (255, 0, 0)
        if depth < 0.5:
            # è“ -> é’
            ratio = depth * 2
            return (255, int(255 * ratio), 0)
        else:
            # é’ -> é»„
            ratio = (depth - 0.5) * 2
            return (int(255 * (1 - ratio)), 255, int(255 * ratio))

    def _draw_gradient_line(self, image: np.ndarray, pt1: tuple, pt2: tuple,
                           color1: tuple, color2: tuple, thickness: int = 2):
        """ç»˜åˆ¶æ¸å˜çº¿æ¡"""
        # ç®€åŒ–ç‰ˆ: ç»˜åˆ¶å¤šæ®µå°çº¿æ¡æ¥æ¨¡æ‹Ÿæ¸å˜
        steps = 10
        for i in range(steps):
            t = i / steps
            x = int(pt1[0] + (pt2[0] - pt1[0]) * t)
            y = int(pt1[1] + (pt2[1] - pt1[1]) * t)
            x_next = int(pt1[0] + (pt2[0] - pt1[0]) * (t + 1/steps))
            y_next = int(pt1[1] + (pt2[1] - pt1[1]) * (t + 1/steps))

            # æ’å€¼é¢œè‰²
            color = tuple([int(c1 + (c2 - c1) * t) for c1, c2 in zip(color1, color2)])

            cv2.line(image, (x, y), (x_next, y_next), color, thickness)

    def shutdown(self):
        """é‡Šæ”¾èµ„æº"""
        super().shutdown()
        if self.hands:
            self.hands.close()


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)

    detector = GestureDetector()

    if detector.initialize():
        cap = cv2.VideoCapture(0)

        print("\n" + "="*60)
        print("  æ‰‹åŠ¿æ£€æµ‹å™¨å·²å¯åŠ¨")
        print("="*60)
        print("\næ”¯æŒçš„æ‰‹åŠ¿:")
        print("  ğŸ–ï¸  å¼ å¼€æ‰‹æŒ  (5æŒ‡) -> TAKEOFF   (èµ·é£)")
        print("  âœŠ  æ¡æ‹³      (0æŒ‡) -> LAND      (é™è½)")
        print("  â˜ï¸  å•æŒ‡      (1æŒ‡) -> HOVER     (æ‚¬åœ)")
        print("  âœŒï¸  Vå­—æ‰‹åŠ¿   (2æŒ‡) -> EXPLORE   (æ¢ç´¢)")
        print("  ğŸ¤Ÿ  ä¸‰æŒ‡      (3æŒ‡) -> FORMATION (ç¼–é˜Ÿ)")
        print("\næ“ä½œæç¤º:")
        print("  - è·ç¦»æ‘„åƒå¤´ 30-60cm")
        print("  - æ‰‹æ”¾åœ¨ç”»é¢ä¸­å¿ƒ")
        print("  - æ¯ä¸ªæ‰‹åŠ¿ä¿æŒ1-2ç§’")
        print("  - æŒ‰ 'q' é€€å‡º")
        print("="*60 + "\n")

        while cap.isOpened():
            success, frame = cap.read()
            if not success:
                break

            # åªæ£€æµ‹ä¸€æ¬¡ï¼Œè·å–æŒ‡ä»¤
            command = detector.run(frame)

            # ä»æ£€æµ‹å™¨è·å–æœ€åä¸€æ¬¡çš„æ£€æµ‹ç»“æœç”¨äºå¯è§†åŒ–
            if hasattr(detector, '_last_detection_result') and detector._last_detection_result:
                landmarks = detector._last_detection_result.get('landmarks')
                if landmarks:
                    # ç»˜åˆ¶æ‰‹éƒ¨å…³é”®ç‚¹
                    detector.mp_draw.draw_landmarks(
                        frame,
                        landmarks,
                        detector.mp_hands.HAND_CONNECTIONS,
                        detector.mp_draw.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),
                        detector.mp_draw.DrawingSpec(color=(255, 0, 0), thickness=2)
                    )

                    # è·å–è°ƒè¯•ä¿¡æ¯
                    landmarks_list = []
                    for lm in landmarks.landmark:
                        landmarks_list.append([lm.x, lm.y, lm.z])

                    # è·å–å·¦å³æ‰‹ä¿¡æ¯
                    handedness = detector._last_detection_result.get('handedness', 'Right')
                    fingers_count = detector._count_fingers_up(landmarks_list, handedness)
                    is_fist = detector._is_fist(landmarks_list)

                    # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯ï¼ˆåŒ…å«å·¦å³æ‰‹ï¼‰
                    debug_text = f"{handedness} Hand | Fingers: {fingers_count}"
                    if is_fist:
                        debug_text += " [FIST]"

                    cv2.putText(
                        frame,
                        debug_text,
                        (10, 110),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (255, 255, 0),
                        1
                    )

            if command and command['confidence'] > 0.5:
                # è·å–æ‰‹åŠ¿ä¿¡æ¯
                gesture_type = command['parameters'].get('gesture_type', 'unknown')
                cmd_name = command['command'].upper() if isinstance(command['command'], str) else command['command'].name

                # æ£€æŸ¥æ˜¯å¦ç»è¿‡å¹³æ»‘å¤„ç†
                is_smoothed = command['parameters'].get('smoothed', False)
                stability = command['parameters'].get('stability', 0.0)
                is_holding = command['parameters'].get('holding', False)

                # æ˜¾ç¤ºæŒ‡ä»¤ï¼ˆæ›´æ¸…æ™°çš„æ ¼å¼ï¼‰
                display_text = f"{gesture_type} -> {cmd_name}"
                if is_holding:
                    display_text += " [HOLD]"
                elif is_smoothed:
                    display_text += f" [S:{stability:.1f}]"

                color = (0, 255, 0) if stability > 0.8 else (0, 255, 255)  # é«˜ç¨³å®šæ€§=ç»¿è‰²ï¼Œå¦åˆ™=é»„è‰²

                cv2.putText(
                    frame,
                    display_text,
                    (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.8,
                    color,
                    2
                )

                # æ˜¾ç¤ºç½®ä¿¡åº¦
                cv2.putText(
                    frame,
                    f"Confidence: {command['confidence']:.2f}",
                    (10, 70),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.6,
                    color,
                    1
                )

                # ç»ˆç«¯æ‰“å°ï¼ˆåŒ…å«ç¨³å®šæ€§ä¿¡æ¯ï¼‰
                status = ""
                if is_holding:
                    status = "[ä¿æŒ]"
                elif is_smoothed:
                    status = f"[ç¨³å®šåº¦:{stability:.2f}]"

                print(f"âœ“ {gesture_type:15s} -> {cmd_name:12s} (ç½®ä¿¡åº¦: {command['confidence']:.2f}) {status}")
            elif command and command['confidence'] == 0.0:
                # æœªæ£€æµ‹åˆ°æ‰‹éƒ¨
                cv2.putText(
                    frame,
                    "No hand detected",
                    (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.8,
                    (0, 0, 255),
                    2
                )

            cv2.imshow('Gesture Detection', frame)

            if cv2.waitKey(5) & 0xFF == ord('q'):
                break

        cap.release()
        cv2.destroyAllWindows()
        detector.shutdown()
